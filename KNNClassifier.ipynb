{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KNNClassifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPpAxhAE761jfvvSAs6yxww"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EbBCpQSXO7Ig"},"source":["import numpy as np\r\n","import urllib.request as ur\r\n","import matplotlib.pyplot as plt\r\n","\r\n","\r\n","class KNNClassifier():\r\n","\r\n","    #initial contructer for the class.\r\n","    def __init__(self, K):\r\n","        self.K = K\r\n","\r\n","    def __repr__(self):\r\n","      return str(self.K)\r\n","\r\n","    # Create a method named “fit” to accept all input data (X) and labels(y). “X”is a matrix that each row is a sample,\r\n","    # and the columns are the features(shape = [num of samples, num of features]). “y”is a vector with the\r\n","    # corresponding class numbers(shape = [num of samples, ])\r\n","    # Example usage: knn.fit(X, y)\r\n","\r\n","    def fit(self, X, y):\r\n","       self.X_train = X\r\n","       self.y_train = y\r\n","\r\n","    # Create another method called “predict” that accepts input samples in a matrix (X) and\r\n","    # returns the predicted classes in a vector. “X” shape is similar to the “X” in “fit” method.\r\n","    # Example usage: predicted_classes = knn.predict(X_new)\r\n","\r\n","    def predict(self, X):\r\n","      self.pred_me = X\r\n","      prediction_lst = []\r\n","      for pred_row in self.pred_me:\r\n","        distances = np.sum((self.X_train - pred_row)**2, axis=1)\r\n","        top_k = np.argsort(distances)[:self.K]\r\n","        counts = np.bincount(self.y_train[top_k].astype('int32'))\r\n","        prediction_lst.append(np.argmax(counts))\r\n","      return prediction_lst\r\n","      \r\n","# end of class"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOEc-y4BxN2n"},"source":["# Start of program\r\n","\r\n","# Load the MNIST data given in the class (mnist.csv)\r\n","url = \"http://www.pjreddie.com/media/files/mnist_train.csv\"\r\n","# file = \"/content/mnist_train.csv\"\r\n","file = ur.urlopen(url)\r\n","data = np.loadtxt(file, delimiter=\",\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LN7BwlmqPEgz"},"source":["# Shuffle the samples\r\n","#data_array = data[:, 1:]\r\n","np.random.shuffle(data)\r\n","\r\n","# Split it to 80% for training and 20% for validation\r\n","training_data = data[:48000, 1:]\r\n","validation_data = data[48000:, 1:]\r\n","\r\n","# Separate labels from input data for both training and validation data\r\n","training_labels = data[:48000, 0]\r\n","validation_labels = data[48000: , 0]\r\n","\r\n","# For each K from 1 to 25 (create a loop), instantiate an object from “KNNClassifier” with that number of neighbors.\r\n","knn_lst = []\r\n","for i in range(1, 26):\r\n","  knn_lst.append(KNNClassifier(i))\r\n","\r\n","# Feed training data using “fit” method\r\n","acc_lst = []\r\n","for i in range(25):\r\n","  knn_lst[i].fit(training_data, training_labels)\r\n","  # Predict the labels for validation data using ‘predict’ method\r\n","  predictions = knn_lst[i].predict(validation_data)\r\n","  #print(predictions)\r\n","  # Compare the predicted labels with the true labels and calculate accuracy:\r\n","  acc_K = np.sum(predictions == validation_labels) / validation_data.shape[0]\r\n","  print(\"custom KNN classification accuracy {} for K={}\".format(acc_K, i+1))\r\n","  acc_lst.append(acc_K)\r\n","  \r\n","# Plot a line graph that shows the accuracy for each “K”\r\n","plt.plot(range(25), acc_lst)\r\n","plt.show()\r\n","\r\n","# Identify which “K” gives the best result\r\n","# Calculate accuracy of the training data for the same “K”\r\n","print(\"The KNNClassifier with the best result k = {} neighbors with and accuracy of {}%\".format((acc_lst.index(max(acc_lst)) + 1), (max(acc_lst) * 100)))"],"execution_count":null,"outputs":[]}]}